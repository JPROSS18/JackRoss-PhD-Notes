{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae67418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import linalg as la\n",
    "from scipy import stats\n",
    "from scipy import spatial as sp\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c152b6",
   "metadata": {},
   "source": [
    "Learning PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e8f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer = torch.tensor([[1, 2, 3], [1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a43f61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75ee8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtensor = np.zeros((10, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01e2d541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 256, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dc2aa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66554795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtensor[].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c68a8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a, b):\n",
    "    c = torch.add(a, b)\n",
    "    d = b - 1\n",
    "    e = torch.multiply(c, d)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1158a66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = 1.5, 2.5\n",
    "out = f(a, b)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd29a2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.module.Module"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8bbde80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDenseLayer(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(OurDenseLayer, self).__init__()\n",
    "        # Define and initialize parameters: a weight matrix W and bias b\n",
    "        # Note that the parameter initialize is random!\n",
    "        self.W = torch.nn.Parameter(torch.randn(num_inputs, num_outputs))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(num_outputs))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''TODO: define the operation for z (hint: use torch.matmul).'''\n",
    "        z = torch.matmul(x, self.W) + self.bias\n",
    "\n",
    "        '''TODO: define the operation for out (hint: use torch.sigmoid).'''\n",
    "        y = torch.sigmoid(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa175f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_outputs = 3\n",
    "layer = OurDenseLayer(num_inputs, num_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1725788",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 1x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m x_input = torch.tensor([[\u001b[32m1\u001b[39m, \u001b[32m2.\u001b[39m]])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_input.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33moutput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jackr\\OneDrive\\Documents\\GitHub\\JackRoss-PhD-Notes\\env1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jackr\\OneDrive\\Documents\\GitHub\\JackRoss-PhD-Notes\\env1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mOurDenseLayer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     10\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''TODO: define the operation for z (hint: use torch.matmul).'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     z = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.bias\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''TODO: define the operation for out (hint: use torch.sigmoid).'''\u001b[39;00m\n\u001b[32m     14\u001b[39m     y = torch.sigmoid(z)\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (2x3 and 1x2)"
     ]
    }
   ],
   "source": [
    "x_input = torch.tensor([[1, 2.]])\n",
    "y = layer(x_input)\n",
    "\n",
    "print(f\"input shape: {x_input.shape}\")\n",
    "print(f\"output shape: {y.shape}\")\n",
    "print(f\"output result: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a7c2093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchdiffeq\n",
      "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
      "Requirement already satisfied: torch>=1.5.0 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from torchdiffeq) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.4.0 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from torchdiffeq) (1.16.2)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from scipy>=1.4.0->torchdiffeq) (2.3.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from torch>=1.5.0->torchdiffeq) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from torch>=1.5.0->torchdiffeq) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from torch>=1.5.0->torchdiffeq) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from torch>=1.5.0->torchdiffeq) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from torch>=1.5.0->torchdiffeq) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from torch>=1.5.0->torchdiffeq) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from torch>=1.5.0->torchdiffeq) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from sympy>=1.13.3->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jackr\\onedrive\\documents\\github\\jackross-phd-notes\\env1\\lib\\site-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.3)\n",
      "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: torchdiffeq\n",
      "Successfully installed torchdiffeq-0.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torchdiffeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a60fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55735c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
